{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from typing import Dict, List, Optional\n",
    "from collections import Counter\n",
    "import os\n",
    "import csv\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from conlleval import evaluate"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:00.449032Z",
     "iopub.execute_input": "2022-02-17T08:25:00.449347Z",
     "iopub.status.idle": "2022-02-17T08:25:00.482131Z",
     "shell.execute_reply.started": "2022-02-17T08:25:00.449262Z",
     "shell.execute_reply": "2022-02-17T08:25:00.481441Z"
    },
    "trusted": true,
    "id": "SWWjBbIZ5LSi"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        # two special tokens for padding and unknown\n",
    "        self.token2idx = {\"<pad>\": 0, \"<unk>\": 1}\n",
    "        self.idx2token = [\"<pad>\", \"<unk>\"]\n",
    "        self.is_fit = False\n",
    "    \n",
    "    @property\n",
    "    def pad_id(self):\n",
    "        return self.token2idx[\"<pad>\"]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)\n",
    "    \n",
    "    def fit(self, train_texts: List[str]):\n",
    "        counter = Counter()\n",
    "        for text in train_texts:\n",
    "            counter.update(text.lower().split())\n",
    "        \n",
    "        # manually set a vocabulary size for the data set\n",
    "        vocab_size = 40000\n",
    "        self.idx2token.extend([token for token, count in counter.most_common(vocab_size - 2)])\n",
    "        for (i, token) in enumerate(self.idx2token):\n",
    "            self.token2idx[token] = i\n",
    "            \n",
    "        self.is_fit = True\n",
    "                \n",
    "    def encode(self, text: str, max_length: Optional[int] = None) -> List[int]:\n",
    "        if not self.is_fit:\n",
    "            raise Exception(\"Please fit the tokenizer on the training tokens\")\n",
    "            \n",
    "        # Split the text into tokens and encode each token using the token2idx mapping\n",
    "        tokens = text.lower().split()\n",
    "        token_ids = [self.token2idx.get(token, self.token2idx[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "        # Pad or truncate the token ids based on the max_length parameter\n",
    "        if max_length is not None:\n",
    "            if len(token_ids) < max_length:\n",
    "                token_ids += [self.token2idx[\"<pad>\"]] * (max_length - len(token_ids))\n",
    "            else:\n",
    "                token_ids = token_ids[:max_length]\n",
    "\n",
    "        return token_ids\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:00.483609Z",
     "iopub.execute_input": "2022-02-17T08:25:00.483925Z",
     "iopub.status.idle": "2022-02-17T08:25:00.494599Z",
     "shell.execute_reply.started": "2022-02-17T08:25:00.483881Z",
     "shell.execute_reply": "2022-02-17T08:25:00.493679Z"
    },
    "trusted": true,
    "id": "u29mNAdI5LSl"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def load_raw_data(filepath: str, with_tags: bool = True):\n",
    "    data = {'text': []}\n",
    "    if with_tags:\n",
    "        data['tags'] = []\n",
    "        with open(filepath) as f:\n",
    "            reader = csv.reader(f)\n",
    "            for text, tags in reader:\n",
    "                data['text'].append(text)\n",
    "                data['tags'].append(tags)\n",
    "    else:\n",
    "        with open(filepath) as f:\n",
    "            for line in f:\n",
    "                data['text'].append(line.strip())\n",
    "    return data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:00.495804Z",
     "iopub.execute_input": "2022-02-17T08:25:00.496201Z",
     "iopub.status.idle": "2022-02-17T08:25:00.504688Z",
     "shell.execute_reply.started": "2022-02-17T08:25:00.496166Z",
     "shell.execute_reply": "2022-02-17T08:25:00.503898Z"
    },
    "trusted": true,
    "id": "7lHbdxRn5LSm"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = Tokenizer()\n",
    "data_dir = os.getcwd()\n",
    "train_raw = load_raw_data(os.path.join(data_dir, \"train.csv\"))\n",
    "val_raw = load_raw_data(os.path.join(data_dir, \"val.csv\"))\n",
    "test_raw = load_raw_data(os.path.join(data_dir, \"test_tokens.txt\"), with_tags=False)\n",
    "# fit the tokenizer on the training tokens\n",
    "tokenizer.fit(train_raw['text'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:00.517671Z",
     "iopub.execute_input": "2022-02-17T08:25:00.518378Z",
     "iopub.status.idle": "2022-02-17T08:25:00.795602Z",
     "shell.execute_reply.started": "2022-02-17T08:25:00.518340Z",
     "shell.execute_reply": "2022-02-17T08:25:00.794913Z"
    },
    "trusted": true,
    "id": "dEuoJh1Q5LSn"
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "[803, 57, 256, 1313, 755, 1813, 0, 0, 0, 0]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtext = 'how are you doing today ?'\n",
    "tokenizer.encode(newtext, max_length=10)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#upload the dataset\n",
    "#for google colb, use this\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ],
   "metadata": {
    "id": "94u1vPV-lbXf"
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class NERDataset: \n",
    "    tag2idx = {'O': 1, 'B-PER': 2, 'I-PER': 3, 'B-ORG': 4, 'I-ORG': 5, 'B-LOC': 6, 'I-LOC': 7, 'B-MISC': 8, 'I-MISC': 9}\n",
    "    idx2tag = ['<pad>', 'O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG','B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "  \n",
    "    def __init__(self, raw_data: Dict[str, List[str]], tokenizer: Tokenizer, max_length: int = 128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.token_ids = []\n",
    "        self.tag_ids = []\n",
    "        self.with_tags = False\n",
    "        for text in raw_data['text']:\n",
    "            self.token_ids.append(tokenizer.encode(text, max_length=max_length))\n",
    "        if 'tags' in raw_data:\n",
    "            self.with_tags = True\n",
    "            for tags in raw_data['tags']:\n",
    "                self.tag_ids.append(self.encode_tags(tags, max_length=max_length))\n",
    "\n",
    "    \n",
    "    def encode_tags(self, tags: str, max_length: Optional[int] = None):\n",
    "        tag_ids = [self.tag2idx[tag] for tag in tags.split()]\n",
    "        if max_length is None:\n",
    "            return tag_ids\n",
    "        # truncate the tags if longer than max_length\n",
    "        if len(tag_ids) > max_length:\n",
    "            return tag_ids[:max_length]\n",
    "        # pad with 0s if shorter than max_length\n",
    "        else:\n",
    "            return tag_ids + [0] * (max_length - len(tag_ids))  # 0 as padding for tags\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.token_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        token_ids = torch.LongTensor(self.token_ids[idx])\n",
    "        mask = token_ids == self.tokenizer.pad_id  # padding tokens\n",
    "        if self.with_tags:\n",
    "            # for training and validation\n",
    "            return token_ids, mask, torch.LongTensor(self.tag_ids[idx])\n",
    "        else:\n",
    "            # for testing\n",
    "            return token_ids, mask\n",
    "        "
   ],
   "metadata": {
    "id": "KzUsGMealyZb"
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tr_data = NERDataset(train_raw, tokenizer)\n",
    "va_data = NERDataset(val_raw, tokenizer)\n",
    "te_data = NERDataset(test_raw, tokenizer)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:02.109558Z",
     "iopub.execute_input": "2022-02-17T08:25:02.109921Z",
     "iopub.status.idle": "2022-02-17T08:25:02.467151Z",
     "shell.execute_reply.started": "2022-02-17T08:25:02.109883Z",
     "shell.execute_reply": "2022-02-17T08:25:02.466435Z"
    },
    "trusted": true,
    "id": "0kMIKu-p5LSo"
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041\n",
      "The Greek socialist party 's executive bureau gave Prime Minister Costas Simitis its backing if he chooses to call snap elections , its general secretary Costas Skandalidis told reporters on Thursday .\n",
      "(tensor([    2,  1638,  1466,   147,    15,   996,  1877,   407,   229,   103,\n",
      "         2415,  2672,    63,  2698,   141,    26, 11142,     7,   629,  2673,\n",
      "          269,     4,    63,   335,   750,  2415,  4652,    90,   524,    13,\n",
      "           70,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "         True,  True,  True,  True,  True,  True,  True,  True]), tensor([1, 8, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 2, 3, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0]))\n"
     ]
    }
   ],
   "source": [
    "samplenum = 265\n",
    "print(len(tr_data))\n",
    "print(train_raw['text'][samplenum])\n",
    "print(tr_data[samplenum])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(embed_size, num_heads, hidden_size,dropout= 0.1)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.layer_norm = nn.LayerNorm(embed_size)\n",
    "        self.linear = nn.Linear(embed_size, 10)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        # src shape: (batch_size, max_length)\n",
    "        # src_mask shape: (batch_size, max_length)\n",
    "        embedded = self.embedding(src)  # shape: (batch_size, max_length, embed_size)\n",
    "        encoded = self.transformer_encoder(embedded.transpose(0, 1), src_key_padding_mask=src_mask).transpose(0, 1)  # shape: (batch_size, max_length, embed_size)\n",
    "        output = self.linear(encoded)  # shape: (batch_size, max_length, num_classes)\n",
    "        return output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:02.468580Z",
     "iopub.execute_input": "2022-02-17T08:25:02.468821Z",
     "iopub.status.idle": "2022-02-17T08:25:02.478006Z",
     "shell.execute_reply.started": "2022-02-17T08:25:02.468786Z",
     "shell.execute_reply": "2022-02-17T08:25:02.477246Z"
    },
    "trusted": true,
    "id": "Jvy2pBQL5LSo"
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def validate(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    device: torch.device,\n",
    "):\n",
    "    acc_metric = torchmetrics.Accuracy(task = 'multiclass', num_classes = 10, compute_on_step=False).to(device)\n",
    "    loss_metric = torchmetrics.MeanMetric(compute_on_step=False).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, input_mask, tags = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "            # output shape: (batch_size, max_length, num_classes)\n",
    "            logits = model(input_ids, input_mask)\n",
    "            # ignore padding index 0 when calculating loss\n",
    "            loss = F.cross_entropy(logits.reshape(-1, 10), tags.reshape(-1), ignore_index=0)\n",
    "                \n",
    "            loss_metric.update(loss, input_mask.numel() - input_mask.sum())\n",
    "            is_active = torch.logical_not(input_mask)  # non-padding elements\n",
    "            # only consider non-padded tokens when calculating accuracy\n",
    "            acc_metric.update(logits[is_active], tags[is_active])\n",
    "\n",
    "    print(f\"| Epoch {epoch+1} | Validate | loss {loss_metric.compute():.4f} | acc {acc_metric.compute():.4f} |!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "    val_loss = loss_metric.compute()\n",
    "\n",
    "    return val_loss\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:03.082423Z",
     "iopub.execute_input": "2022-02-17T08:25:03.082694Z",
     "iopub.status.idle": "2022-02-17T08:25:03.091306Z",
     "shell.execute_reply.started": "2022-02-17T08:25:03.082660Z",
     "shell.execute_reply": "2022-02-17T08:25:03.090373Z"
    },
    "trusted": true,
    "id": "Y5Eaibzu5LSp"
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#modify as required\n",
    "def train(\n",
    "    model: nn.Module, \n",
    "    dataloader: DataLoader, \n",
    "    optimizer: optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    epoch: int,\n",
    "):\n",
    "    acc_metric = torchmetrics.Accuracy(task = 'multiclass', num_classes = 10, compute_on_step=False).to(device)\n",
    "    loss_metric = torchmetrics.MeanMetric(compute_on_step=False).to(device)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    # loop through all batches in the training\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids, input_mask, tags = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # output shape: (batch_size, max_length, num_classes)\n",
    "        logits = model(input_ids, input_mask)\n",
    "        # ignore padding index 0 when calculating loss\n",
    "        loss = F.cross_entropy(logits.reshape(-1, 10), tags.reshape(-1), ignore_index=0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_metric.update(loss, input_mask.numel() - input_mask.sum())\n",
    "        is_active = torch.logical_not(input_mask)  # non-padding elements\n",
    "        # only consider non-padded tokens when calculating accuracy\n",
    "        acc_metric.update(logits[is_active], tags[is_active])\n",
    "    \n",
    "    print(f\"| Epoch {epoch+1} | Train | loss {loss_metric.compute():.4f} | acc {acc_metric.compute():.4f} |\")\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:03.092754Z",
     "iopub.execute_input": "2022-02-17T08:25:03.093232Z",
     "iopub.status.idle": "2022-02-17T08:25:03.104319Z",
     "shell.execute_reply.started": "2022-02-17T08:25:03.093195Z",
     "shell.execute_reply": "2022-02-17T08:25:03.103543Z"
    },
    "trusted": true,
    "id": "qQtTOXRA5LSp"
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def predict(model: nn.Module, dataloader: DataLoader, device: torch.device) -> List[List[str]]:\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    idx2tag = ['<pad>', 'O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            input_ids, src_mask = batch[0].to(device), batch[1].to(device)\n",
    "            logits = model(input_ids, src_mask=src_mask)\n",
    "            batch_preds = logits.argmax(dim=-1).tolist()\n",
    "            for i, tags in enumerate(batch_preds):\n",
    "                # Get the true length of the unpadded sequence using the input mask\n",
    "                seq_len = 128 - src_mask[i].sum().item()  # .item() converts a one-element tensor to a scalar\n",
    "                # print(src_mask[i])\n",
    "                # print(seq_len)\n",
    "                # Convert the predicted tag indices to tag labels\n",
    "                tag_preds = [idx2tag[idx] for idx in tags[:seq_len]]  # Slice the predicted tags to seq_len\n",
    "                # print(tag_preds)\n",
    "                # Append the tag predictions to the list of predictions\n",
    "                preds.append(tag_preds)\n",
    "\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def init_weights(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "#\n",
    "# def init_weights(module):\n",
    "#     if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "#         nn.init.kaiming_uniform_(module.weight)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 48.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 1 | Train | loss 0.3059 | acc 0.9179 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 146.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 1 | Validate | loss 0.2547 | acc 0.9320 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 50.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 2 | Train | loss 0.0954 | acc 0.9696 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 150.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 2 | Validate | loss 0.2584 | acc 0.9371 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 50.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 3 | Train | loss 0.0578 | acc 0.9803 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 145.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 3 | Validate | loss 0.2995 | acc 0.9375 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 51.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 4 | Train | loss 0.0435 | acc 0.9853 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 146.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 4 | Validate | loss 0.3157 | acc 0.9380 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 50.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 5 | Train | loss 0.0330 | acc 0.9888 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 150.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 5 | Validate | loss 0.3041 | acc 0.9371 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 50.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 6 | Train | loss 0.0273 | acc 0.9908 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 153.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 6 | Validate | loss 0.3608 | acc 0.9374 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 439/439 [00:08<00:00, 51.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 7 | Train | loss 0.0232 | acc 0.9923 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:00<00:00, 150.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch 7 | Validate | loss 0.3923 | acc 0.9373 |!!!!!!!!!!!!!!!!!!!!!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:01<00:00, 100.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 54612 tokens with 5942 phrases; found: 6002 phrases; correct: 4274.\n",
      "accuracy:  69.67%; (non-O)\n",
      "accuracy:  94.10%; precision:  71.21%; recall:  71.93%; FB1:  71.57\n",
      "              LOC: precision:  85.16%; recall:  83.12%; FB1:  84.13  1793\n",
      "             MISC: precision:  74.03%; recall:  74.51%; FB1:  74.27  928\n",
      "              ORG: precision:  62.11%; recall:  63.68%; FB1:  62.89  1375\n",
      "              PER: precision:  63.27%; recall:  65.47%; FB1:  64.35  1906\n"
     ]
    },
    {
     "data": {
      "text/plain": "(71.20959680106631, 71.9286435543588, 71.56731413261889)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simple trainer\n",
    "torch.manual_seed(321)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "#hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EMBED_SIZE = 256\n",
    "NUM_HEADS = 4\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 3\n",
    "LEARNING_RATE = 0.000456008621520148\n",
    "EPOCHS = 7\n",
    "\n",
    "# data loaders\n",
    "train_dataloader = DataLoader(tr_data, batch_size = BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(va_data, batch_size = BATCH_SIZE)\n",
    "test_dataloader = DataLoader(te_data, batch_size = BATCH_SIZE)\n",
    "\n",
    "# move the model to device\n",
    "model = TransformerModel(vocab_size = len(tokenizer),\n",
    "    embed_size = EMBED_SIZE,\n",
    "    num_heads = NUM_HEADS,\n",
    "    hidden_size = HIDDEN_SIZE,\n",
    "    num_layers = NUM_LAYERS,).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr= LEARNING_RATE)\n",
    "model.apply(init_weights)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train(model, train_dataloader, optimizer, device, epoch)\n",
    "    validate(model, val_dataloader, device)\n",
    "\n",
    "\n",
    "prediction = predict(model, val_dataloader, device)\n",
    "pred_tags = []\n",
    "for tags in prediction:\n",
    "    pred_tags.extend(tags)\n",
    "    pred_tags.append('O')\n",
    "\n",
    "true_tags = []\n",
    "for tags in val_raw['tags']:\n",
    "    true_tags.extend(tags.strip().split())\n",
    "    true_tags.append('O')\n",
    "\n",
    "evaluate(true_tags, pred_tags)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9. Mauricio Gugelmin ( Brazil ) , Reynard Ford Cosworth , 54.762\n",
      "O B-PER I-PER O B-LOC O O B-ORG I-ORG I-ORG O O\n",
      "['O', 'B-PER', 'I-PER', 'O', 'B-LOC', 'O', 'O', 'I-PER', 'B-MISC', 'I-PER', 'O', 'I-PER']\n"
     ]
    }
   ],
   "source": [
    "samplenum = 2157\n",
    "\n",
    "print(val_raw['text'][samplenum])\n",
    "print(val_raw['tags'][samplenum])\n",
    "print(prediction[samplenum])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# YOU SHOULD NOT CHANGE THIS CODEBLOCK\n",
    "# make prediction on the test set and save to submission.txt\n",
    "preds = predict(model, test_dataloader, device)\n",
    "with open(\"submission.txt\", \"w\") as f:\n",
    "    for tags in preds:\n",
    "        f.write(\" \".join(tags) + \"\\n\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:25:45.395550Z",
     "iopub.execute_input": "2022-02-17T08:25:45.395822Z",
     "iopub.status.idle": "2022-02-17T08:25:46.111937Z",
     "shell.execute_reply.started": "2022-02-17T08:25:45.395787Z",
     "shell.execute_reply": "2022-02-17T08:25:46.111234Z"
    },
    "trusted": true,
    "id": "dVt102qy5LSs"
   },
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:00<00:00, 127.46it/s]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "pwd"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:27:24.950886Z",
     "iopub.execute_input": "2022-02-17T08:27:24.951166Z",
     "iopub.status.idle": "2022-02-17T08:27:24.957143Z",
     "shell.execute_reply.started": "2022-02-17T08:27:24.951135Z",
     "shell.execute_reply": "2022-02-17T08:27:24.956414Z"
    },
    "trusted": true,
    "id": "jJOtOKyR5LSs"
   },
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\UCSB\\\\CS190I\\\\mp2'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "ls"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-02-17T08:27:30.109566Z",
     "iopub.execute_input": "2022-02-17T08:27:30.109841Z",
     "iopub.status.idle": "2022-02-17T08:27:30.796831Z",
     "shell.execute_reply.started": "2022-02-17T08:27:30.109811Z",
     "shell.execute_reply": "2022-02-17T08:27:30.795875Z"
    },
    "trusted": true,
    "id": "5VquJfjq5LSs"
   },
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is 新加卷\n",
      " Volume Serial Number is 76AF-40CE\n",
      "\n",
      " Directory of D:\\UCSB\\CS190I\\mp2\n",
      "\n",
      "03/17/2023  10:37 PM    <DIR>          .\n",
      "03/15/2023  03:49 PM    <DIR>          ..\n",
      "03/17/2023  10:35 PM    <DIR>          .idea\n",
      "03/17/2023  09:35 PM    <DIR>          __pycache__\n",
      "03/17/2023  09:33 PM           270,227 autobert.ipynb\n",
      "03/16/2023  07:43 PM           160,863 autotune.ipynb\n",
      "03/16/2023  12:55 AM            51,492 bert.ipynb\n",
      "03/17/2023  09:35 PM             7,502 conlleval.py\n",
      "03/17/2023  09:54 PM    <DIR>          flagged\n",
      "03/17/2023  10:08 PM         1,929,345 full.ipynb\n",
      "03/17/2023  10:18 PM             2,848 stupid methos.ipynb\n",
      "03/17/2023  10:37 PM           125,188 submission.txt\n",
      "03/17/2023  10:37 PM            29,352 submission_template.ipynb\n",
      "03/17/2023  09:33 PM            45,992 template.ipynb\n",
      "03/17/2023  08:47 PM            10,532 test.py\n",
      "03/10/2023  10:27 PM           246,547 test_tokens.txt\n",
      "03/10/2023  10:27 PM         1,668,107 train.csv\n",
      "03/17/2023  10:18 PM           129,689 truthfilexxxxx.txt\n",
      "03/10/2023  10:27 PM           420,479 val.csv\n",
      "              14 File(s)      5,098,163 bytes\n",
      "               5 Dir(s)  1,351,977,177,088 bytes free\n"
     ]
    }
   ]
  }
 ]
}
